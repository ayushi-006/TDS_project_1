{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. brianyu28,PatrickAlphaC,KeithGalli,CharlesCreativeContent,timbl\n",
      "2. evan,dpickett,tel,radical,joshuaclayton\n",
      "3. mit,other,apache-2.0\n",
      "4. NORTHEASTERN UNIVERSITY\n",
      "5. JavaScript\n",
      "6. C#\n",
      "7. SQL\n",
      "8. nikomatsakis,ccoenraets,KeithGalli,rstudio,pluskid\n",
      "9. 0.168\n",
      "10. 1.221\n",
      "11. nan\n",
      "12. 129.637\n",
      "13. -5.674\n",
      "14. berquist,lizbur10,burtbeckwith,jimkang,rwaldron\n",
      "15. 0.111\n",
      "16. 4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Read the CSV files\n",
    "users_df = pd.read_csv('users.csv')\n",
    "repos_df = pd.read_csv('repositories.csv')\n",
    "\n",
    "# 1. Top 5 users by followers\n",
    "def top_followers():\n",
    "    return ','.join(users_df.nlargest(5, 'followers')['login'].tolist())\n",
    "\n",
    "# 2. 5 earliest registered users\n",
    "def earliest_users():\n",
    "    users_df['created_at'] = pd.to_datetime(users_df['created_at'])\n",
    "    return ','.join(users_df.nsmallest(5, 'created_at')['login'].tolist())\n",
    "\n",
    "# 3. Most popular licenses\n",
    "def popular_licenses():\n",
    "    return ','.join(repos_df['license_name'].value_counts().head(3).index.tolist())\n",
    "\n",
    "# 4. Most common company\n",
    "def most_common_company():\n",
    "    return users_df['company'].mode()[0]\n",
    "\n",
    "# 5. Most popular language\n",
    "def most_popular_language():\n",
    "    return repos_df['language'].mode()[0]\n",
    "\n",
    "# 6. Second most popular language for users after 2020\n",
    "def second_popular_language_post_2020():\n",
    "    users_df['created_at'] = pd.to_datetime(users_df['created_at'])\n",
    "    recent_users = users_df[users_df['created_at'].dt.year > 2020]['login']\n",
    "    recent_repos = repos_df[repos_df['login'].isin(recent_users)]\n",
    "    return recent_repos['language'].value_counts().index[1]\n",
    "\n",
    "# 7. Language with highest average stars\n",
    "def highest_avg_stars_language():\n",
    "    return repos_df.groupby('language')['stargazers_count'].mean().idxmax()\n",
    "\n",
    "# 8. Top 5 by leader_strength\n",
    "def top_leader_strength():\n",
    "    users_df['leader_strength'] = users_df['followers'] / (1 + users_df['following'])\n",
    "    return ','.join(users_df.nlargest(5, 'leader_strength')['login'].tolist())\n",
    "\n",
    "# 9. Correlation between followers and repos\n",
    "def followers_repos_correlation():\n",
    "    return round(users_df['followers'].corr(users_df['public_repos']), 3)\n",
    "\n",
    "# 10. Regression slope of followers on repos\n",
    "from sklearn.linear_model import LinearRegression\n",
    "def followers_repos_regression():\n",
    "    X = users_df[['public_repos']]\n",
    "    y = users_df['followers']\n",
    "    reg = LinearRegression().fit(X, y)\n",
    "    return round(reg.coef_[0], 3)\n",
    "\n",
    "# 11. Correlation between projects and wiki\n",
    "def projects_wiki_correlation():\n",
    "    repos_df['has_projects'] = repos_df['has_projects'].map({'true': 1, 'false': 0})\n",
    "    repos_df['has_wiki'] = repos_df['has_wiki'].map({'true': 1, 'false': 0})\n",
    "    return round(repos_df['has_projects'].corr(repos_df['has_wiki']), 3)\n",
    "\n",
    "# 12. Hireable users following difference\n",
    "def hireable_following_diff():\n",
    "    hireable = users_df[users_df['hireable'] == 'true']['following'].mean()\n",
    "    not_hireable = users_df[users_df['hireable'] != 'true']['following'].mean()\n",
    "    return round(hireable - not_hireable, 3)\n",
    "\n",
    "# 13. Bio length correlation with followers\n",
    "def bio_followers_correlation():\n",
    "    users_df['bio_words'] = users_df['bio'].fillna('').str.split().str.len()\n",
    "    users_with_bio = users_df[users_df['bio_words'] > 0]\n",
    "    X = users_with_bio[['bio_words']]\n",
    "    y = users_with_bio['followers']\n",
    "    reg = LinearRegression().fit(X, y)\n",
    "    return round(reg.coef_[0], 3)\n",
    "\n",
    "# 14. Top weekend repository creators\n",
    "def weekend_repo_creators():\n",
    "    repos_df['created_at'] = pd.to_datetime(repos_df['created_at'])\n",
    "    weekend_repos = repos_df[repos_df['created_at'].dt.dayofweek.isin([5, 6])]\n",
    "    weekend_counts = weekend_repos['login'].value_counts()\n",
    "    return ','.join(weekend_counts.head(5).index.tolist())\n",
    "\n",
    "# 15. Hireable email sharing difference\n",
    "def hireable_email_diff():\n",
    "    hireable_email = users_df[users_df['hireable'] == 'true']['email'].notna().mean()\n",
    "    other_email = users_df[users_df['hireable'] != 'true']['email'].notna().mean()\n",
    "    return round(hireable_email - other_email, 3)\n",
    "\n",
    "# 16. Most common surname\n",
    "def most_common_surname():\n",
    "    users_df['surname'] = users_df['name'].str.split().str[-1]\n",
    "    return users_df['surname'].value_counts().iloc[0]\n",
    "\n",
    "# Print all results\n",
    "print(\"1.\", top_followers())\n",
    "print(\"2.\", earliest_users())\n",
    "print(\"3.\", popular_licenses())\n",
    "print(\"4.\", most_common_company())\n",
    "print(\"5.\", most_popular_language())\n",
    "print(\"6.\", second_popular_language_post_2020())\n",
    "print(\"7.\", highest_avg_stars_language())\n",
    "print(\"8.\", top_leader_strength())\n",
    "print(\"9.\", followers_repos_correlation())\n",
    "print(\"10.\", followers_repos_regression())\n",
    "print(\"11.\", projects_wiki_correlation())\n",
    "print(\"12.\", hireable_following_diff())\n",
    "print(\"13.\", bio_followers_correlation())\n",
    "print(\"14.\", weekend_repo_creators())\n",
    "print(\"15.\", hireable_email_diff())\n",
    "print(\"16.\", most_common_surname())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few codes with correct answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Williams: 4\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "# Counter to store surname frequencies\n",
    "surname_counter = Counter()\n",
    "\n",
    "# Open the users.csv file and read data\n",
    "with open('users.csv', 'r', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    \n",
    "    for row in reader:\n",
    "        name = row.get('name', '').strip()\n",
    "        if name:  # Ignore missing names\n",
    "            # Split the name by whitespace and get the last word as the surname\n",
    "            surname = name.split()[-1]\n",
    "            surname_counter[surname] += 1\n",
    "\n",
    "# Find the maximum frequency of surnames\n",
    "if surname_counter:\n",
    "    max_count = max(surname_counter.values())\n",
    "    # Get all surnames with the maximum frequency\n",
    "    most_common_surnames = [surname for surname, count in surname_counter.items() if count == max_count]\n",
    "    # Sort surnames alphabetically\n",
    "    most_common_surnames.sort()\n",
    "    # Output the result\n",
    "    print(f\"{', '.join(most_common_surnames)}: {max_count}\")\n",
    "else:\n",
    "    print(\"No names found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users with bios: 264\n",
      "Bio length range: 4 to 160\n",
      "Followers range: 119 to 13203\n",
      "R-squared: 0.001\n",
      "\n",
      "Regression slope: -0.912\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "def analyze_bio_followers_correlation(users_csv_path='users.csv'):\n",
    "    # Read the data\n",
    "    df = pd.read_csv(users_csv_path)\n",
    "    \n",
    "    # Filter out rows without bios\n",
    "    df = df[df['bio'].notna() & (df['bio'] != '')]\n",
    "    \n",
    "    # Calculate bio length in Unicode characters\n",
    "    df['bio_length'] = df['bio'].str.len()\n",
    "    \n",
    "    # Prepare data for regression\n",
    "    X = df['bio_length'].values.reshape(-1, 1)\n",
    "    y = df['followers'].values\n",
    "    \n",
    "    # Perform linear regression\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Get the slope rounded to 3 decimal places\n",
    "    slope = round(model.coef_[0], 3)\n",
    "    \n",
    "    # Print debug information\n",
    "    print(f\"Number of users with bios: {len(df)}\")\n",
    "    print(f\"Bio length range: {df['bio_length'].min()} to {df['bio_length'].max()}\")\n",
    "    print(f\"Followers range: {df['followers'].min()} to {df['followers'].max()}\")\n",
    "    print(f\"R-squared: {model.score(X, y):.3f}\")\n",
    "    \n",
    "    return slope\n",
    "\n",
    "# Calculate the regression slope\n",
    "result = analyze_bio_followers_correlation()\n",
    "print(f\"\\nRegression slope: {result:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the list to store programming languages\n",
    "languages = []\n",
    "\n",
    "# Read the CSV file with UTF-8 encoding\n",
    "with open('repositories.csv', 'r', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    \n",
    "    # Iterate through the rows in the CSV\n",
    "    for row in reader:\n",
    "        # Parse the created_at field\n",
    "        created_at = row.get('created_at', '').strip()\n",
    "        \n",
    "        # Convert the date string to a datetime object\n",
    "        if created_at:\n",
    "            user_join_date = datetime.strptime(created_at, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "            \n",
    "            # Check if the user joined after 2020\n",
    "            if user_join_date.year > 2020:\n",
    "                # Get the language field and clean it up\n",
    "                language = row.get('language', '').strip()\n",
    "                if language:\n",
    "                    languages.append(language)\n",
    "\n",
    "# Count the occurrence of each language\n",
    "language_counts = Counter(languages)\n",
    "\n",
    "# Find the two most common languages\n",
    "most_common_languages = language_counts.most_common(2)\n",
    "\n",
    "# Print the second most common language\n",
    "if len(most_common_languages) >= 2:\n",
    "    print(most_common_languages[1][0])  # Second most common language\n",
    "else:\n",
    "    print(\"Not enough language data found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
